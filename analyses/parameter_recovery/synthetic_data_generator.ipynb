{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d15a73-40ed-4a21-9684-136a22eb4325",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e91655f-19e8-4189-80cd-ce57d9573499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from tqdm import tqdm\n",
    "import hssm\n",
    "import random\n",
    "from hssm.distribution_utils import make_distribution\n",
    "from hssm.likelihoods import DDM\n",
    "from scipy.stats import pearsonr\n",
    "import pytensor.tensor as pt\n",
    "from pytensor.scan import scan\n",
    "from scipy.stats import norm, halfnorm, gamma\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9446020-1a59-4bd8-8ee5-10d93efd1d0d",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d30d085-bb73-4189-b263-63f9d50f11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rounds = 160\n",
    "n_indi_param_sets = 21 \n",
    "n_group_param_sets = 30\n",
    "\n",
    "fixed_ndt = 0.25\n",
    "wald_prior_class = \"log_normal_prior_centered\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c339b42-b3d4-466b-96a5-45f1361e25f2",
   "metadata": {},
   "source": [
    "### Import fitted parameters and gambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc59609b-9494-4eeb-9ff1-59ed52de4a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gambles downloaded\n"
     ]
    }
   ],
   "source": [
    "# Experiment version\n",
    "exp_version = 2\n",
    "\n",
    "#Nextcloud credentials\n",
    "username = 'algarrid'\n",
    "password = 'faunistico'\n",
    "\n",
    "# URL of the CSV file \n",
    "file_url = 'https://cloud.ilabt.imec.be/remote.php/dav/files/af741990-37f9-103d-9441-9bec5c4808a7/ExperimentsData/risky_dm_2/Gambles/gambles_risky_dm_2.csv'\n",
    "\n",
    "# Make a request to get the file content\n",
    "response = requests.get(file_url, auth=(username, password))\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Stream the content directly into a pandas DataFrame\n",
    "    csv_content = StringIO(response.text)\n",
    "    df_gambles = pd.read_csv(csv_content)\n",
    "\n",
    "    # Now `df` is your DataFrame containing the CSV data\n",
    "    print(\"Gambles downloaded\")  # Example: print the first few rows\n",
    "else:\n",
    "    print(f\"Failed to retrieve the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107c15e-f7ec-4ddb-9985-ba344bf5d900",
   "metadata": {},
   "source": [
    "## Import group fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0917a589-b06d-49fd-a071-03ccf2f8fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wald_group_fitted_params = pd.read_csv(f'../model_fitting/fitted_parameters/wald/group_fitted_params_wald_{wald_prior_class}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29358f2b-5b3e-4ec4-a405-c756b0f6d8f4",
   "metadata": {},
   "source": [
    "## Generate parameter sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0ef45-7870-4274-8a37-63ab053761fc",
   "metadata": {},
   "source": [
    "##### Generate group-level parameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beabd44a-38bf-4b75-9952-55f0e5f72a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for g in range(n_group_param_sets):\n",
    "\n",
    "    if wald_prior_class in [\"log_normal_prior_centered\", \"log_normal_prior_non_centered\"]:\n",
    "\n",
    "        group_log_beta0_mu_mean = df_wald_group_fitted_params['group_log_beta0_mu_mean'].iloc[0]\n",
    "        group_log_beta0_mu_sd = df_wald_group_fitted_params['group_log_beta0_mu_sd'].iloc[0]\n",
    "        group_log_beta0_mu = norm(loc=group_log_beta0_mu_mean, scale=group_log_beta0_mu_sd).rvs()\n",
    "\n",
    "        group_log_beta1_mu_mean = df_wald_group_fitted_params['group_log_beta1_mu_mean'].iloc[0]\n",
    "        group_log_beta1_mu_sd = df_wald_group_fitted_params['group_log_beta1_mu_sd'].iloc[0]\n",
    "        group_log_beta1_mu = norm(loc=group_log_beta1_mu_mean, scale=group_log_beta1_mu_sd).rvs()\n",
    "\n",
    "        group_log_beta2_mu_mean = df_wald_group_fitted_params['group_log_beta2_mu_mean'].iloc[0]\n",
    "        group_log_beta2_mu_sd = df_wald_group_fitted_params['group_log_beta2_mu_sd'].iloc[0]\n",
    "        group_log_beta2_mu = norm(loc=group_log_beta2_mu_mean, scale=group_log_beta2_mu_sd).rvs()\n",
    "        \n",
    "        group_log_drift_mu_mean = df_wald_group_fitted_params['group_log_drift_mu_mean'].iloc[0]\n",
    "        group_log_drift_mu_sd = df_wald_group_fitted_params['group_log_drift_mu_sd'].iloc[0]\n",
    "        group_log_drift_mu = norm(loc=group_log_drift_mu_mean, scale=group_log_drift_mu_sd).rvs()\n",
    "\n",
    "        group_log_beta0_sigma_mean = df_wald_group_fitted_params['group_log_beta0_sigma_mean'].iloc[0]\n",
    "        group_log_beta0_sigma_sd = df_wald_group_fitted_params['group_log_beta0_sigma_sd'].iloc[0]\n",
    "        group_log_beta0_sigma = norm(loc=group_log_beta0_sigma_mean, scale=group_log_beta0_sigma_sd).rvs()\n",
    "\n",
    "        group_log_beta1_sigma_mean = df_wald_group_fitted_params['group_log_beta1_sigma_mean'].iloc[0]\n",
    "        group_log_beta1_sigma_sd = df_wald_group_fitted_params['group_log_beta1_sigma_sd'].iloc[0]\n",
    "        group_log_beta1_sigma = norm(loc=group_log_beta1_sigma_mean, scale=group_log_beta1_sigma_sd).rvs()\n",
    "\n",
    "        group_log_beta2_sigma_mean = df_wald_group_fitted_params['group_log_beta2_sigma_mean'].iloc[0]\n",
    "        group_log_beta2_sigma_sd = df_wald_group_fitted_params['group_log_beta2_sigma_sd'].iloc[0]\n",
    "        group_log_beta2_sigma = norm(loc=group_log_beta2_sigma_mean, scale=group_log_beta2_sigma_sd).rvs()\n",
    "        \n",
    "        group_log_drift_sigma_mean = df_wald_group_fitted_params['group_log_drift_sigma_mean'].iloc[0]\n",
    "        group_log_drift_sigma_sd = df_wald_group_fitted_params['group_log_drift_sigma_sd'].iloc[0]\n",
    "        group_log_drift_sigma = norm(loc=group_log_drift_sigma_mean, scale=group_log_drift_sigma_sd).rvs()\n",
    "    \n",
    "        rows.append({\n",
    "            'group_parameter_set_ID': g,\n",
    "            'group_log_beta0_mu': group_log_beta0_mu,\n",
    "            'group_log_beta1_mu': group_log_beta1_mu,\n",
    "            'group_log_beta2_mu': group_log_beta2_mu,\n",
    "            'group_log_drift_mu': group_log_drift_mu,\n",
    "            'group_log_beta0_sigma': group_log_beta0_sigma,\n",
    "            'group_log_beta1_sigma': group_log_beta1_sigma,\n",
    "            'group_log_beta2_sigma': group_log_beta2_sigma,\n",
    "            'group_log_drift_sigma': group_log_drift_sigma,\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        alpha_beta0 = 3.45\n",
    "        beta_beta0 = 0.5\n",
    "        group_beta0_mu = gamma(a=alpha_beta0, scale=1/beta_beta0).rvs()\n",
    "    \n",
    "        alpha_beta1 = 2.6\n",
    "        beta_beta1 = 3.2\n",
    "        group_beta1_mu = gamma(a=alpha_beta1, scale=1/beta_beta1).rvs()\n",
    "    \n",
    "        alpha_beta2 = 2.6\n",
    "        beta_beta2 = 3.2\n",
    "        group_beta2_mu = gamma(a=alpha_beta2, scale=1/beta_beta2).rvs()\n",
    "    \n",
    "        alpha_drift = 4.7\n",
    "        beta_drift = 3.6\n",
    "        group_drift_mu = gamma(a=alpha_drift, scale=1/beta_drift).rvs()\n",
    "        \n",
    "    \n",
    "        group_beta0_sigma = halfnorm(scale=0.5).rvs()\n",
    "        group_beta1_sigma = halfnorm(scale=0.5).rvs()\n",
    "        group_beta2_sigma = halfnorm(scale=0.5).rvs()\n",
    "        group_drift_sigma = halfnorm(scale=0.5).rvs()\n",
    "    \n",
    "    \n",
    "    \n",
    "        # ===== subject-level Gamma draws (positive, no logs) =====\n",
    "        #beta0 = pm.Gamma(\"indi_beta0\", mu=beta0_mu, sigma=beta0_sigma, dims=\"subject\")\n",
    "        #beta1 = pm.Gamma(\"indi_beta1\", mu=beta1_mu, sigma=beta1_sigma, dims=\"subject\")\n",
    "        #beta2 = pm.Gamma(\"indi_beta2\", mu=beta2_mu, sigma=beta2_sigma, dims=\"subject\")\n",
    "        #drift = pm.Gamma(\"indi_drift\", mu=drift_mu, sigma=drift_sigma, dims=\"subject\")\n",
    "    \n",
    "    \n",
    "        rows.append({\n",
    "            'group_parameter_set_ID': g,\n",
    "            'synthetic_group_beta0_mu': group_beta0_mu,\n",
    "            'synthetic_group_beta1_mu': group_beta1_mu,\n",
    "            'synthetic_group_beta2_mu': group_beta2_mu,\n",
    "            'synthetic_group_beta0_sigma': group_beta0_sigma,\n",
    "            'synthetic_group_beta1_sigma': group_beta1_sigma,\n",
    "            'synthetic_group_beta2_sigma': group_beta2_sigma,\n",
    "            'synthetic_group_drift_mu': group_drift_mu,\n",
    "            'synthetic_group_drift_sigma': group_drift_sigma,\n",
    "        })\n",
    "\n",
    "\n",
    "df_synthetic_group_parameters = pd.DataFrame(rows)\n",
    "\n",
    "out_dir = Path(\"synthetic_data\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = out_dir / f\"wald_model_synthetic_group_parameters_{wald_prior_class}.csv\"\n",
    "df_synthetic_group_parameters.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af53458-2ab2-48d8-9271-8f7245a2d65d",
   "metadata": {},
   "source": [
    "##### Generate individual-level parameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc2bdf2-50d7-491c-a043-1d1e5506430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for g in range(n_group_param_sets):\n",
    "\n",
    "    group_level_params_df = df_synthetic_group_parameters[df_synthetic_group_parameters['group_parameter_set_ID']==g]\n",
    "\n",
    "    if wald_prior_class in [\"log_normal_prior_non_centered\",\"log_normal_prior_centered\"]:\n",
    "        \n",
    "        group_log_beta0_mu = group_level_params_df['group_log_beta0_mu'].iloc[0]\n",
    "        group_log_beta1_mu = group_level_params_df['group_log_beta1_mu'].iloc[0]\n",
    "        group_log_beta2_mu = group_level_params_df['group_log_beta2_mu'].iloc[0]\n",
    "    \n",
    "        group_log_beta0_sigma = group_level_params_df['group_log_beta0_sigma'].iloc[0]\n",
    "        group_log_beta1_sigma = group_level_params_df['group_log_beta1_sigma'].iloc[0]\n",
    "        group_log_beta2_sigma = group_level_params_df['group_log_beta2_sigma'].iloc[0]\n",
    "    \n",
    "        group_log_drift_mu = group_level_params_df['group_log_drift_mu'].iloc[0]\n",
    "        group_log_drift_sigma = group_level_params_df['group_log_drift_sigma'].iloc[0]\n",
    "\n",
    "\n",
    "        for i in range(n_indi_param_sets):\n",
    "            \n",
    "            # Sample\n",
    "            if wald_prior_class == \"log_normal_prior_centered\":\n",
    "                \n",
    "                indi_log_beta0 = norm(loc=group_log_beta0_mu, scale=group_log_beta0_sigma).rvs()\n",
    "                indi_log_beta1 = norm(loc=group_log_beta1_mu, scale=group_log_beta1_sigma).rvs()\n",
    "                indi_log_beta2 = norm(loc=group_log_beta2_mu, scale=group_log_beta2_sigma).rvs()\n",
    "                indi_log_drift = norm(loc=group_log_drift_mu, scale=group_log_drift_sigma).rvs()\n",
    "                \n",
    "            elif wald_prior_class == \"log_normal_prior_non_centered\":\n",
    "                z_b0 = norm(loc=0, scale=1).rvs()\n",
    "                z_b1 = norm(loc=0, scale=1).rvs()\n",
    "                z_b2 = norm(loc=0, scale=1).rvs()\n",
    "                z_d  = norm(loc=0, scale=1).rvs()\n",
    "    \n",
    "                indi_log_beta0 = group_log_beta0_mu + group_log_beta0_sigma * z_b0\n",
    "                indi_log_beta1 = group_log_beta1_mu + group_log_beta1_sigma * z_b1\n",
    "                indi_log_beta2 = group_log_beta2_mu + group_log_beta2_sigma * z_b2\n",
    "                indi_log_drift = group_log_drift_mu + group_log_drift_sigma * z_d\n",
    "    \n",
    "    \n",
    "            # Transform\n",
    "            indi_beta0 = np.exp(indi_log_beta0) \n",
    "            indi_beta1 = np.exp(indi_log_beta1) \n",
    "            indi_beta2 = np.exp(indi_log_beta2) \n",
    "            indi_drift = np.exp(indi_log_drift) \n",
    "    \n",
    "            # Synthetic DDM parameters\n",
    "    \n",
    "            synthetic_a = np.random.uniform(0.5,3.5)\n",
    "            synthetic_t = np.random.uniform(0.2,2)\n",
    "            synthetic_v_diff_p = np.random.uniform(0,4)\n",
    "            synthetic_v_diff_x = np.random.uniform(0,4)\n",
    "            synthetic_v_diff_ev = np.random.uniform(0,4)\n",
    "    \n",
    "    \n",
    "            rows.append({\n",
    "                'group_parameter_set_ID': g,\n",
    "                'synthetic_par_ID': i,\n",
    "                'synthetic_indi_beta0': indi_beta0,\n",
    "                'synthetic_indi_beta1': indi_beta1,\n",
    "                'synthetic_indi_beta2': indi_beta2,\n",
    "                'synthetic_indi_drift': indi_drift,\n",
    "                'synthetic_indi_a': synthetic_a,\n",
    "                'synthetic_indi_t': synthetic_t,\n",
    "                'synthetic_indi_v_diff_p': synthetic_v_diff_p,\n",
    "                'synthetic_indi_v_diff_x': synthetic_v_diff_x,\n",
    "                'synthetic_indi_v_diff_ev': synthetic_v_diff_ev,\n",
    "            })\n",
    "    else:\n",
    "        group_beta0_mu = group_level_params_df['synthetic_group_beta0_mu'].iloc[0]\n",
    "        group_beta1_mu = group_level_params_df['synthetic_group_beta1_mu'].iloc[0]\n",
    "        group_beta2_mu = group_level_params_df['synthetic_group_beta2_mu'].iloc[0]\n",
    "    \n",
    "        group_beta0_sigma = group_level_params_df['synthetic_group_beta0_sigma'].iloc[0]\n",
    "        group_beta1_sigma = group_level_params_df['synthetic_group_beta1_sigma'].iloc[0]\n",
    "        group_beta2_sigma = group_level_params_df['synthetic_group_beta2_sigma'].iloc[0]\n",
    "    \n",
    "        group_drift_mu = group_level_params_df['synthetic_group_drift_mu'].iloc[0]\n",
    "        group_drift_sigma = group_level_params_df['synthetic_group_drift_sigma'].iloc[0]\n",
    "    \n",
    "    \n",
    "        for i in range(n_indi_param_sets):\n",
    "            \n",
    "    \n",
    "            # sMple\n",
    "    \n",
    "            beta0 = gamma(a=(group_beta0_mu/group_beta0_sigma)**2, scale=(group_beta0_sigma**2)/group_beta0_mu).rvs() \n",
    "            beta1 = gamma(a=(group_beta1_mu/group_beta1_sigma)**2, scale=(group_beta1_sigma**2)/group_beta1_mu).rvs() \n",
    "            beta2 = gamma(a=(group_beta2_mu/group_beta2_sigma)**2, scale=(group_beta2_sigma**2)/group_beta2_mu).rvs() \n",
    "            drift = gamma(a=(group_drift_mu/group_drift_sigma)**2, scale=(group_drift_sigma**2)/group_drift_mu).rvs() \n",
    "    \n",
    "            # Synthetic DDM parameters\n",
    "    \n",
    "            synthetic_a = np.random.uniform(0.5,3.5)\n",
    "            synthetic_t = np.random.uniform(0.2,2)\n",
    "            synthetic_d_p = np.random.uniform(0,4)\n",
    "            synthetic_d_x = np.random.uniform(0,4)\n",
    "            synthetic_d_ev = np.random.uniform(0,4)\n",
    "    \n",
    "    \n",
    "            rows.append({\n",
    "                'group_parameter_set_ID': g,\n",
    "                'synthetic_par_ID': i,\n",
    "                'synthetic_indi_beta0': beta0,\n",
    "                'synthetic_indi_beta1': beta1,\n",
    "                'synthetic_indi_beta2': beta2,\n",
    "                'synthetic_indi_drift': drift,\n",
    "                'synthetic_indi_a': synthetic_a,\n",
    "                'synthetic_indi_t': synthetic_t,\n",
    "                'synthetic_indi_v_diff_p': synthetic_v_diff_p,\n",
    "                'synthetic_indi_v_diff_x': synthetic_v_diff_x,\n",
    "                'synthetic_indi_v_diff_ev': synthetic_v_diff_ev,\n",
    "            })\n",
    "\n",
    "df_synthetic_indi_parameters = pd.DataFrame(rows)\n",
    "\n",
    "out_dir = Path(\"synthetic_data\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = out_dir / f\"wald_model_synthetic_indi_parameters_{wald_prior_class}.csv\"\n",
    "df_synthetic_indi_parameters.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33a60d-9a80-4310-9d4b-f7221e4888ba",
   "metadata": {},
   "source": [
    "## Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d0bea4-0544-41c7-9e54-9cb452f3a11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [25:47<00:00, 51.58s/it]\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_list = []\n",
    "\n",
    "for g in tqdm(range(n_group_param_sets)):\n",
    "\n",
    "    df_group_indi_parameters = df_synthetic_indi_parameters[df_synthetic_indi_parameters['group_parameter_set_ID']==g]\n",
    "\n",
    "    for i in range(n_indi_param_sets):\n",
    "        # Get individual level parameters\n",
    "        df_par_params = df_group_indi_parameters[df_group_indi_parameters['synthetic_par_ID']==i]\n",
    "\n",
    "        # Get Wald model parameters\n",
    "        synthetic_beta0 = df_par_params['synthetic_indi_beta0'].iloc[0]\n",
    "        synthetic_beta1 = df_par_params['synthetic_indi_beta1'].iloc[0]\n",
    "        synthetic_beta2 = df_par_params['synthetic_indi_beta2'].iloc[0]\n",
    "        synthetic_wald_drift = df_par_params['synthetic_indi_drift'].iloc[0]\n",
    "        \n",
    "        synthetic_wald_ndt = fixed_ndt \n",
    "\n",
    "        # Get DDM parameters\n",
    "        synthetic_a = df_par_params['synthetic_indi_a'].iloc[0]\n",
    "        synthetic_ddm_t = df_par_params['synthetic_indi_t'].iloc[0]\n",
    "        synthetic_v_diff_p = df_par_params['synthetic_indi_v_diff_p'].iloc[0]\n",
    "        synthetic_v_diff_x = df_par_params['synthetic_indi_v_diff_x'].iloc[0]\n",
    "        synthetic_v_diff_ev = df_par_params['synthetic_indi_v_diff_ev'].iloc[0]\n",
    "\n",
    "        # Decide a random order of gamble presentation:\n",
    "        random_gamble_presentation = np.random.permutation(np.arange(1, 161))\n",
    "\n",
    "\n",
    "        for n, gam in enumerate(random_gamble_presentation):\n",
    "         \n",
    "            gamble_df = df_gambles[df_gambles['GambleNumber']==gam]\n",
    "    \n",
    "            diff_x = gamble_df[\"lot_1_val\"].iloc[0] - gamble_df[\"lot_0_val\"].iloc[0]\n",
    "            \n",
    "            diff_p = gamble_df[\"lot_1_prob\"].iloc[0] - gamble_df[\"lot_0_prob\"].iloc[0]\n",
    "    \n",
    "            diff_x = diff_x/100\n",
    "            diff_p = diff_p/100\n",
    "    \n",
    "            ev_0 = (gamble_df[\"lot_0_val\"].iloc[0]/100) * (gamble_df[\"lot_0_prob\"].iloc[0]/100)\n",
    "            ev_1 = (gamble_df[\"lot_1_val\"].iloc[0]/100) * (gamble_df[\"lot_1_prob\"].iloc[0]/100)\n",
    "    \n",
    "            diff_ev = ev_1 - ev_0\n",
    "    \n",
    "            #round_v = synthetic_v_diff_p*diff_p + synthetic_v_diff_x*diff_x \n",
    "            round_v = synthetic_v_diff_ev*diff_ev + synthetic_v_diff_p*diff_p + synthetic_v_diff_x*diff_x \n",
    "    \n",
    "            #Simulate ddm\n",
    "            ddm_sim = hssm.simulate_data(\n",
    "                model=\"ddm\",\n",
    "                theta=dict(\n",
    "                    v = round_v,\n",
    "                    a = synthetic_a,\n",
    "                    z = 0.5,\n",
    "                    t = synthetic_ddm_t,\n",
    "                ),\n",
    "                size=1,\n",
    "                random_state = random.randint(0, 999999)\n",
    "            )\n",
    "            \n",
    "            sim_rt = ddm_sim['rt'].iloc[0]\n",
    "            sim_response = ddm_sim['response'].iloc[0]\n",
    "\n",
    "            # Figure out the deadline\n",
    "            original_deadline = gamble_df['Deadline'].iloc[0]\n",
    "    \n",
    "            if sim_rt < original_deadline:\n",
    "                sim_deadline = original_deadline\n",
    "            else:\n",
    "                if sim_rt < 8:\n",
    "                    sim_deadline = 8\n",
    "                else:\n",
    "                    if sim_rt < 10:\n",
    "                        sim_deadline = 10\n",
    "                    else:\n",
    "                        sim_deadline = sim_rt\n",
    "        \n",
    "            sim_wt = sim_deadline - sim_rt\n",
    "    \n",
    "            # Calculate Wald distribution parameters\n",
    "            alpha_threshold = synthetic_beta0 + synthetic_beta1*sim_rt + synthetic_beta2*sim_wt\n",
    "\n",
    "            mu = alpha_threshold/synthetic_wald_drift\n",
    "            \n",
    "            lam = alpha_threshold**2\n",
    "    \n",
    "            # Simulate reproduced time using PyMC's Wald distribution\n",
    "            sim_repro_t = pm.draw(pm.Wald.dist(mu=mu, \n",
    "                                               lam=lam, \n",
    "                                               alpha = synthetic_wald_ndt), \n",
    "                                  draws=1).item() \n",
    "            \n",
    "            #Save synthetic data\n",
    "            synthetic_data_list.append({\n",
    "                'group_parameter_set_ID': g,\n",
    "                'synthetic_par_ID': i,\n",
    "                'Round_ID': n,\n",
    "                'Gamble_ID': gam,\n",
    "                'rt': sim_rt,\n",
    "                'response': sim_response,\n",
    "                'repro_t': sim_repro_t,\n",
    "                'wt': sim_wt,\n",
    "                'diff_x': diff_x,\n",
    "                'diff_p': diff_p,\n",
    "                'diff_ev': diff_ev\n",
    "            })\n",
    "\n",
    "\n",
    "# Convert the list into a DataFrame\n",
    "df_synthetic_data = pd.DataFrame(synthetic_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202200c0-09a4-4f26-b126-a3b4bd4d0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the folder exists\n",
    "outdir = \"synthetic_data\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# save to CSV\n",
    "out_path = os.path.join(outdir, f\"synthetic_data_{wald_prior_class}.csv\")\n",
    "df_synthetic_data.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd27c0e-efad-4fe7-b20e-1958703c84d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
